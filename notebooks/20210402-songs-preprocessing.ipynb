{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = os.getcwd().replace(os.path.basename(os.getcwd()), \"\")\n",
    "DATA_PATH = os.path.join(PROJECT_PATH, \"data\")\n",
    "SONGS_H5_PATH = os.path.join(DATA_PATH, \"songs-h5-unpacked\")\n",
    "SONGS_FEATURES_PATH = os.path.join(DATA_PATH, \"songs-features_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SONGS_H5_PATH):\n",
    "    os.makedirs(SONGS_H5_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                          \r"
     ]
    }
   ],
   "source": [
    "# unpack h5 files from nested directories\n",
    "for root, dirs, files in tqdm(os.walk(DATA_PATH), leave=False):    \n",
    "    for file in files:\n",
    "        if file.endswith('.h5'):\n",
    "            os.rename(os.path.join(root, file), os.path.join(SONGS_H5_PATH, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_h5(\n",
    "    h5: h5py._hl.files.File) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "    \"\"\"Convert Yahoo million songs h5 file into Python dictionary.\"\"\"\n",
    "    l1 = dict()\n",
    "    for k1, v1 in h5.items():\n",
    "        l2 = dict()\n",
    "        for k2, v2 in v1.items():\n",
    "            v2 = np.array(v2)\n",
    "            if (np.prod(v2.shape) == 1) & (v2.dtype.fields is not None):\n",
    "                l3 = dict()\n",
    "                for k3, v3 in zip(list(v2.dtype.fields.keys()), v2[0]):\n",
    "                    l3[k3] = v3\n",
    "                l2[k2] = l3\n",
    "            else:\n",
    "                l2[k2] = np.array(v2)\n",
    "        l1[k1] = l2 \n",
    "        \n",
    "    return deepcopy(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_h5 = h5py.File(os.path.join(SONGS_H5_PATH, np.random.choice(os.listdir(SONGS_H5_PATH))), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_h5 = process_h5(some_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(dict_: Dict, prefix_sep = \"__\") -> Dict:\n",
    "    \"\"\"FLatten nested dictionary.\"\"\"\n",
    "    flattened_dict = dict()\n",
    "    \n",
    "    def flattener(dict_: Dict, parent_key=None):\n",
    "        for k,v in dict_.items():\n",
    "            if type(v) == dict:\n",
    "                if parent_key is None:\n",
    "                    flattener(v, k)\n",
    "                else:\n",
    "                    flattener(v, f\"{parent_key}{prefix_sep}{k}\")\n",
    "            else:\n",
    "                flattened_dict[f\"{parent_key}{prefix_sep}{k}\"] = v\n",
    "                \n",
    "    flattener(dict_)\n",
    "    \n",
    "    return deepcopy(flattened_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_h5 = flatten_dict(processed_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flattened_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis__songs__analysis_sample_rate 22050\n",
      "analysis__songs__danceability 0.0\n",
      "analysis__songs__duration 409.91302\n",
      "analysis__songs__end_of_fade_in 0.485\n",
      "analysis__songs__energy 0.0\n",
      "analysis__songs__idx_bars_confidence 0\n",
      "analysis__songs__idx_bars_start 0\n",
      "analysis__songs__idx_beats_confidence 0\n",
      "analysis__songs__idx_beats_start 0\n",
      "analysis__songs__idx_sections_confidence 0\n",
      "analysis__songs__idx_sections_start 0\n",
      "analysis__songs__idx_segments_confidence 0\n",
      "analysis__songs__idx_segments_loudness_max 0\n",
      "analysis__songs__idx_segments_loudness_max_time 0\n",
      "analysis__songs__idx_segments_loudness_start 0\n",
      "analysis__songs__idx_segments_pitches 0\n",
      "analysis__songs__idx_segments_start 0\n",
      "analysis__songs__idx_segments_timbre 0\n",
      "analysis__songs__idx_tatums_confidence 0\n",
      "analysis__songs__idx_tatums_start 0\n",
      "analysis__songs__key 1\n",
      "analysis__songs__key_confidence 0.342\n",
      "analysis__songs__loudness -12.066\n",
      "analysis__songs__mode 1\n",
      "analysis__songs__mode_confidence 0.379\n",
      "analysis__songs__start_of_fade_out 402.088\n",
      "analysis__songs__tempo 124.988\n",
      "analysis__songs__time_signature 4\n",
      "analysis__songs__time_signature_confidence 0.958\n",
      "metadata__songs__artist_7digitalid 44243\n",
      "metadata__songs__artist_familiarity 0.4893181616985732\n",
      "metadata__songs__artist_hotttnesss 0.25116592509237207\n",
      "metadata__songs__artist_latitude nan\n",
      "metadata__songs__artist_longitude nan\n",
      "metadata__songs__artist_playmeid -1\n",
      "metadata__songs__idx_artist_terms 0\n",
      "metadata__songs__idx_similar_artists 0\n",
      "metadata__songs__release_7digitalid 208424\n",
      "metadata__songs__song_hotttnesss 0.0\n",
      "metadata__songs__track_7digitalid 2259155\n",
      "musicbrainz__songs__idx_artist_mbtags 0\n",
      "musicbrainz__songs__year 0\n"
     ]
    }
   ],
   "source": [
    "keys_to_keep = []\n",
    "for k, v in flattened_h5.items():\n",
    "    if isinstance(v, (np.int32, np.float32, int, float)):\n",
    "        keys_to_keep.append(k)\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_keep = [\n",
    "    'analysis__songs__analysis_sample_rate',\n",
    "    'analysis__songs__danceability',\n",
    "    'analysis__songs__duration',\n",
    "    'analysis__songs__end_of_fade_in',\n",
    "    'analysis__songs__energy',\n",
    "    'analysis__songs__key',\n",
    "    'analysis__songs__key_confidence',\n",
    "    'analysis__songs__loudness',\n",
    "    'analysis__songs__mode_confidence',\n",
    "    'analysis__songs__start_of_fade_out',\n",
    "    'analysis__songs__tempo',\n",
    "    'analysis__songs__time_signature',\n",
    "    'analysis__songs__time_signature_confidence',\n",
    "    'metadata__songs__artist_familiarity',\n",
    "    'metadata__songs__artist_hotttnesss',\n",
    "    'metadata__songs__song_hotttnesss',\n",
    "    'musicbrainz__songs__year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SONGS_FEATURES_PATH):\n",
    "    os.makedirs(SONGS_FEATURES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                          \r"
     ]
    }
   ],
   "source": [
    "song_features = []\n",
    "# size = 600\n",
    "# parts = int(len(os.listdir(SONGS_H5_PATH))/size) \n",
    "\n",
    "# if len(os.listdir(SONGS_H5_PATH))//size > 0:\n",
    "#     parts += 1\n",
    "\n",
    "for i, file in tqdm(enumerate(os.listdir(SONGS_H5_PATH)), leave=False):\n",
    "    h5 = h5py.File(os.path.join(SONGS_H5_PATH, file), \"r\")\n",
    "    h5 = flatten_dict(process_h5(h5))\n",
    "    h5 = {k:v for k,v in h5.items() if k in keys_to_keep}\n",
    "    h5 = {k:v if not isinstance(v, np.int32) else int(v) for k,v in h5.items()}\n",
    "    h5[\"file_id\"] = os.path.basename(file).replace(\".h5\", \"\")    \n",
    "    song_features.append(h5)\n",
    "#     with open(os.path.join(SONGS_FEATURES_PATH, file.replace(\"h5\", \"json\")), 'w') as fp:\n",
    "#         json.dump(h5, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(song_features).to_csv(os.path.join(DATA_PATH, \"song_features.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "million-songs",
   "language": "python",
   "name": "million-songs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
